kind: ConfigMap
apiVersion: v1
metadata:
  name: clusterplex-pms-config
  labels:
    app.kubernetes.io/name: clusterplex-pms-config
    app.kubernetes.io/part-of: clusterplex
data:
  VERSION: docker
  TZ: ${TIMEZONE}
  PGID: '1000'
  PUID: '1000'
  DOCKER_MODS: 'ghcr.io/pabloromeo/clusterplex_dockermod:latest'
  ORCHESTRATOR_URL: 'http://clusterplex-orchestrator:3500'
  PMS_SERVICE: "clusterplex-pms"
  PMS_PORT: "32400"
  TRANSCODER_VERBOSE: '1'
  TRANSCODE_OPERATING_MODE: remote
  LOCAL_RELAY_ENABLED: '1'
  LOCAL_RELAY_PORT: "32499"
---
kind: ConfigMap
apiVersion: v1
metadata:
  name: clusterplex-orchestrator-config
  labels:
    app.kubernetes.io/name: clusterplex-orchestrator-config
    app.kubernetes.io/part-of: clusterplex
data:
  TZ: ${TIMEZONE}
  LISTENING_PORT: '3500'
  WORKER_SELECTION_STRATEGY: LOAD_TASKS
---
kind: ConfigMap
apiVersion: v1
metadata:
  name: clusterplex-worker-config
  labels:
    app.kubernetes.io/name: clusterplex-worker-config
    app.kubernetes.io/part-of: clusterplex
data:
  TZ: ${TIMEZONE}
  PGID: '1000'
  PUID: '1000'
  VERSION: docker
  DOCKER_MODS: 'ghcr.io/pabloromeo/clusterplex_worker_dockermod:1.4.16'
  ORCHESTRATOR_URL: 'http://clusterplex-orchestrator:3500'
  LISTENING_PORT: '3501'
  STAT_CPU_INTERVAL: '10000'
  EAE_SUPPORT: '1'
  FFMPEG_HWACCEL: 'vaapi'
---
apiVersion: v1
kind: ConfigMap
metadata:
  name: clusterplex-worker-init-script
  labels:
    app.kubernetes.io/name: clusterplex-worker-init-script
    app.kubernetes.io/part-of: clusterplex
data:
  setup-gpu-drivers.sh: |
    #!/bin/bash
    set -e

    echo "Setting up GPU driver cache for workers..."

    # Create the cache directory structure
    CACHE_DIR="/config/Library/Application Support/Plex Media Server/Cache/va-dri-linux-x86_64"
    mkdir -p "$CACHE_DIR"

    # Check if drivers already exist
    if [ -f "$CACHE_DIR/iHD_drv_video.so" ] || [ -f "$CACHE_DIR/i965_drv_video.so" ]; then
        echo "Drivers already cached"
        ls -la "$CACHE_DIR"
        exit 0
    fi

    # First, let's see what's available in the container
    echo "Searching for available GPU drivers in the container..."

    # Search for any VA-API drivers
    for search_path in /usr/lib/plexmediaserver/lib/dri /usr/lib/x86_64-linux-gnu/dri /usr/lib/dri /usr/local/lib/dri; do
        if [ -d "$search_path" ]; then
            echo "Found driver directory: $search_path"
            ls -la "$search_path" 2>/dev/null || true
        fi
    done

    # Check if drivers exist in Plex's bundled location
    if [ -d "/usr/lib/plexmediaserver/lib/dri" ]; then
        echo "Copying all drivers from Plex bundle..."
        cp -r /usr/lib/plexmediaserver/lib/dri/* "$CACHE_DIR/" 2>/dev/null || true
    fi

    # Copy specific Intel drivers if found
    # Intel iHD driver (newer Intel GPUs - Gen 8+)
    for driver_path in \
        "/usr/lib/plexmediaserver/lib/dri/iHD_drv_video.so" \
        "/usr/lib/x86_64-linux-gnu/dri/iHD_drv_video.so" \
        "/usr/lib/dri/iHD_drv_video.so"; do
        if [ -f "$driver_path" ]; then
            cp "$driver_path" "$CACHE_DIR/"
            echo "Copied iHD driver from $driver_path"
            break
        fi
    done

    # Intel i965 driver (older Intel GPUs - Gen 4-9)
    for driver_path in \
        "/usr/lib/plexmediaserver/lib/dri/i965_drv_video.so" \
        "/usr/lib/x86_64-linux-gnu/dri/i965_drv_video.so" \
        "/usr/lib/dri/i965_drv_video.so"; do
        if [ -f "$driver_path" ]; then
            cp "$driver_path" "$CACHE_DIR/"
            echo "Copied i965 driver from $driver_path"
            break
        fi
    done

    # If no drivers found in standard locations, try to install them
    if [ ! -f "$CACHE_DIR/iHD_drv_video.so" ] && [ ! -f "$CACHE_DIR/i965_drv_video.so" ]; then
        echo "No drivers found in standard locations. Attempting to install..."

        # Check if we can install packages (works in Ubuntu-based containers)
        if command -v apt-get &> /dev/null; then
            echo "Installing Intel Media Driver..."
            apt-get update && apt-get install -y intel-media-va-driver-non-free i965-va-driver || true

            # After installation, try copying again
            for driver_path in \
                "/usr/lib/x86_64-linux-gnu/dri/iHD_drv_video.so" \
                "/usr/lib/dri/iHD_drv_video.so"; do
                if [ -f "$driver_path" ]; then
                    cp "$driver_path" "$CACHE_DIR/"
                    echo "Copied iHD driver from $driver_path after installation"
                    break
                fi
            done

            for driver_path in \
                "/usr/lib/x86_64-linux-gnu/dri/i965_drv_video.so" \
                "/usr/lib/dri/i965_drv_video.so"; do
                if [ -f "$driver_path" ]; then
                    cp "$driver_path" "$CACHE_DIR/"
                    echo "Copied i965 driver from $driver_path after installation"
                    break
                fi
            done
        fi
    fi

    # Set proper permissions
    chown -R 1000:1000 "/config/Library"
    chmod -R 755 "$CACHE_DIR"

    echo "GPU driver cache setup complete. Contents:"
    ls -la "$CACHE_DIR"

    # Verify we have at least one driver
    if [ ! -f "$CACHE_DIR/iHD_drv_video.so" ] && [ ! -f "$CACHE_DIR/i965_drv_video.so" ]; then
        echo "WARNING: No Intel GPU drivers were found or installed!"
        echo "Hardware transcoding may not work properly."
    fi
---
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: clusterplex-config
  labels:
    app.kubernetes.io/name: clusterplex-config
    app.kubernetes.io/part-of: clusterplex
spec:
  accessModes:
  - ReadWriteOnce
  resources:
    requests:
      storage: "10Gi"
---
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: clusterplex-transcode
  labels:
    app.kubernetes.io/name: clusterplex-transcode
    app.kubernetes.io/part-of: clusterplex
spec:
  accessModes:
  - ReadWriteMany
  resources:
    requests:
      storage: "10Gi"
  storageClassName: rook-cephfs
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: clusterplex-pms
  labels:
    app.kubernetes.io/name: clusterplex-pms
    app.kubernetes.io/part-of: clusterplex
spec:
  replicas: 1
  selector:
    matchLabels:
      app.kubernetes.io/name: clusterplex-pms
      app.kubernetes.io/part-of: clusterplex
  template:
    metadata:
      labels:
        app.kubernetes.io/name: clusterplex-pms
        app.kubernetes.io/part-of: clusterplex
    spec:
      affinity:
        podAntiAffinity:
          preferredDuringSchedulingIgnoredDuringExecution:
          - podAffinityTerm:
              labelSelector:
                matchLabels:
                  name: clusterplex-worker
              topologyKey: kubernetes.io/hostname
            weight: 50
          - podAffinityTerm:
              labelSelector:
                matchLabels:
                  name: clusterplex-pms
              topologyKey: kubernetes.io/hostname
            weight: 100
      containers:
      - name: plex
        image: lscr.io/linuxserver/plex:latest
        startupProbe:
          httpGet:
            path: /identity
            scheme: HTTPS
            port: 32400
          failureThreshold: 30
          periodSeconds: 10
        readinessProbe:
          httpGet:
            path: /identity
            scheme: HTTPS
            port: 32400
          initialDelaySeconds: 15
          timeoutSeconds: 5
        livenessProbe:
          httpGet:
            path: /identity
            scheme: HTTPS
            port: 32400
          initialDelaySeconds: 10
          timeoutSeconds: 10
        ports:
          - name: pms
            containerPort: 32400
          - name: relay
            containerPort: 32499
        envFrom:
        - configMapRef:
            name: clusterplex-pms-config
        volumeMounts:
        - name: data
          mountPath: /data
        - name: config
          mountPath: /config
        - name: transcode
          mountPath: /transcode
        # resources:          # adapt requests and limits to your needs
        #   requests:
        #     cpu: 300m
        #     memory: 256Mi
        #   limits:
        #     cpu: 2000m
        #     memory: 512Mi
      volumes:
      - name: data
        persistentVolumeClaim:
          claimName: "media-share"
      - name: config
        persistentVolumeClaim:
          claimName: "clusterplex-config"
      - name: transcode
        persistentVolumeClaim:
          claimName: "clusterplex-transcode"
---
apiVersion: v1
kind: Service
metadata:
  name: clusterplex-pms
  labels:
    app.kubernetes.io/name: clusterplex-pms
    app.kubernetes.io/part-of: clusterplex
spec:
  type: ClusterIP
  ports:
    - name: pms
      port: 32400
      protocol: TCP
      targetPort: pms
    - name: relay
      port: 32499
      protocol: TCP
      targetPort: relay
  selector:
    app.kubernetes.io/name: clusterplex-pms
    app.kubernetes.io/part-of: clusterplex
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: clusterplex-orchestrator
  labels:
    app.kubernetes.io/name: clusterplex-orchestrator
    app.kubernetes.io/part-of: clusterplex
spec:
  replicas: 1
  selector:
    matchLabels:
      app.kubernetes.io/name: clusterplex-orchestrator
      app.kubernetes.io/part-of: clusterplex
  template:
    metadata:
      labels:
        app.kubernetes.io/name: clusterplex-orchestrator
        app.kubernetes.io/part-of: clusterplex
    spec:
      containers:
      - name: plex
        image: ghcr.io/pabloromeo/clusterplex_orchestrator:latest
        startupProbe:
          httpGet:
            path: /health
            port: 3500
          failureThreshold: 3
          periodSeconds: 10
        readinessProbe:
          httpGet:
            path: /health
            port: 3500
          initialDelaySeconds: 5
          timeoutSeconds: 5
        livenessProbe:
          httpGet:
            path: /health
            port: 3500
          initialDelaySeconds: 5
          timeoutSeconds: 10
        ports:
          - name: orchestrator
            containerPort: 3500
        envFrom:
        - configMapRef:
            name: clusterplex-orchestrator-config
        resources:            # adapt requests and limits to your needs
          requests:
            cpu: 200m
            memory: 32Mi
          limits:
            cpu: 500m
            memory: 64Mi
---
apiVersion: v1
kind: Service
metadata:
  name: clusterplex-orchestrator
  labels:
    app.kubernetes.io/name: clusterplex-orchestrator
    app.kubernetes.io/part-of: clusterplex
spec:
  type: ClusterIP
  ports:
    - name: orchestrator
      port: 3500
      protocol: TCP
      targetPort: orchestrator
  selector:
    app.kubernetes.io/name: clusterplex-orchestrator
    app.kubernetes.io/part-of: clusterplex
---
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: clusterplex-worker
  labels:
    app.kubernetes.io/name: clusterplex-worker
    app.kubernetes.io/part-of: clusterplex
spec:
  serviceName: clusterplex-worker-service
  podManagementPolicy: Parallel
  replicas: 2
  selector:
    matchLabels:
      app.kubernetes.io/name: clusterplex-worker
      app.kubernetes.io/part-of: clusterplex
  template:
    metadata:
      labels:
        app.kubernetes.io/name: clusterplex-worker
        app.kubernetes.io/part-of: clusterplex
    spec:
      affinity:
        podAntiAffinity:
          preferredDuringSchedulingIgnoredDuringExecution:
          - podAffinityTerm:
              labelSelector:
                matchLabels:
                  name: clusterplex-worker
              topologyKey: kubernetes.io/hostname
            weight: 100
          - podAffinityTerm:
              labelSelector:
                matchLabels:
                  name: clusterplex-pms
              topologyKey: kubernetes.io/hostname
            weight: 50
      initContainers:
      - name: setup-gpu-drivers
        image: lscr.io/linuxserver/plex:latest
        command: ["/bin/bash", "/scripts/setup-gpu-drivers.sh"]
        securityContext:
          privileged: true
        volumeMounts:
        - name: worker-config
          mountPath: /config
        - name: init-scripts
          mountPath: /scripts
      containers:
      - name: plex-worker
        image: lscr.io/linuxserver/plex:latest
        securityContext:
          privileged: true
        startupProbe:
          httpGet:
            path: /health
            port: 3501
          failureThreshold: 40
          periodSeconds: 10
        readinessProbe:
          httpGet:
            path: /health
            port: 3501
          initialDelaySeconds: 60
          timeoutSeconds: 5
        livenessProbe:
          httpGet:
            path: /health
            port: 3501
          initialDelaySeconds: 10
          timeoutSeconds: 10
        ports:
          - name: worker
            containerPort: 3501
        envFrom:
        - configMapRef:
            name: clusterplex-worker-config
        volumeMounts:
        - name: data
          mountPath: /data
        - name: worker-config
          mountPath: /config
        - name: codecs
          mountPath: /codecs
        - name: transcode
          mountPath: /transcode
        resources:
          requests:
            gpu.intel.com/i915: "10"
          limits:
            gpu.intel.com/i915: "10"
        # resources:              # adapt requests and limits to your needs
        #   requests:
        #     cpu: 500m
        #     memory: 200Mi
        #   limits:
        #     cpu: 3000m
        #     memory: 800Mi
      volumes:
      - name: data
        persistentVolumeClaim:
          claimName: "media-share"
      - name: transcode
        persistentVolumeClaim:
          claimName: "clusterplex-transcode"
      - name: worker-config
        emptyDir: {}
      - name: init-scripts
        configMap:
          name: clusterplex-worker-init-script
          defaultMode: 0755
  volumeClaimTemplates:
    - metadata:
        name: codecs
        labels:
          app.kubernetes.io/name: clusterplex-codecs
          app.kubernetes.io/part-of: clusterplex
      spec:
        accessModes: [ "ReadWriteOnce" ]
        resources:
          requests:
            storage: 1Gi
        # specify your storage class
        #storageClassName: longhorn
---
apiVersion: gateway.networking.k8s.io/v1
kind: HTTPRoute
metadata:
  name: clusterplex
  namespace: media
  annotations:
    item.homer.rajsingh.info/name: "ClusterPlex"
    item.homer.rajsingh.info/subtitle: "Media Server"
    item.homer.rajsingh.info/logo: "https://raw.githubusercontent.com/walkxcode/dashboard-icons/main/svg/plex.svg"
    item.homer.rajsingh.info/keywords: "media, server, streaming"
    service.homer.rajsingh.info/name: "Media"
    service.homer.rajsingh.info/icon: "fas fa-tv"
spec:
  parentRefs:
    - group: gateway.networking.k8s.io
      kind: Gateway
      name: private
      namespace: home
    - group: gateway.networking.k8s.io
      kind: Gateway
      name: ts
      namespace: home
    - group: gateway.networking.k8s.io
      kind: Gateway
      name: public
      namespace: home
  hostnames:
    - "clusterplex.${CLUSTER_DOMAIN}"
  rules:
    - backendRefs:
        - group: ""
          kind: Service
          name: clusterplex-pms
          port: 32400
          weight: 1
      filters:
        - type: RequestHeaderModifier
          requestHeaderModifier:
            set:
              - name: "X-Forwarded-Proto"
                value: "https"
        - type: ResponseHeaderModifier
          responseHeaderModifier:
            remove:
              - "Server"
              - "X-XSS-Protection"
            set:
              - name: "X-Content-Type-Options"
                value: "nosniff"
              - name: "X-Frame-Options"
                value: "SAMEORIGIN"
              - name: "Cache-Control"
                value: "no-transform"
      matches:
        - path:
            type: PathPrefix
            value: /